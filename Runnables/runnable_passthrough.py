"""
Using RunnablePassthrough we can print the intermediate output of the chain. In the below example, we are printing the joke generated by the first prompt before passing it to the second prompt for explanation.
"""

from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough
from dotenv import load_dotenv

load_dotenv()

SYSTEM_RULE = (
    "Do NOT include reasoning, chain-of-thought, or <think> tags. "
    "Return ONLY the final answer."
)

prompt1 = ChatPromptTemplate.from_messages([
    ("system", SYSTEM_RULE),
    ("human", "Write a short joke about {topic}.")
])

prompt2 = ChatPromptTemplate.from_messages([
    ("system", SYSTEM_RULE),
    ("human", "Explain the joke :\n{joke}")
])

model = ChatGroq(model="qwen/qwen3-32b")

parser = StrOutputParser()

joke_chain = RunnableSequence(prompt1, model, parser)
parallel_chain = RunnableParallel({
    "joke": RunnablePassthrough(),
    "explaination": RunnableSequence(prompt2, model, parser)
})

final_chain = RunnableSequence(joke_chain, parallel_chain)
output = final_chain.invoke({'topic': 'dogs'})
print(output)